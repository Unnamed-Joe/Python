{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed50548a",
   "metadata": {},
   "source": [
    "# Sixth homework for computational mathematics course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a60500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8bc135",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73d84b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial log(P)}{\\partial \\sigma} = \\sum_i \\frac{\\partial log(p_i)}{\\partial \\sigma} = \\sum_i (\\frac{(x_i-\\mu)^2}{\\sigma^3} - \\frac{1}{\\sigma}) = 0\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial log(P)}{\\partial \\mu} = \\sum_i \\frac{\\partial log(p_i)}{\\partial \\mu} = \\sum_i \\frac{x_i-\\mu}{\\sigma^2} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{\\sum_i x_i}{N}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{\\sum_i (x_i - \\mu)^2}{N}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b46d7",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bcd3ac",
   "metadata": {},
   "source": [
    "$$\n",
    "P(\\lambda|m) = \\frac{P_{\\lambda}(m)\\cdot P(\\lambda)}{\\int P_{\\lambda'}(m)\\cdot P(\\lambda')d\\lambda'} = \\frac{\\frac{\\lambda^m}{m!}e^{-\\lambda}}{\\int\\frac{\\lambda^m}{m!}e^{-\\lambda}d\\lambda'} = \\frac{\\lambda^me^{-\\lambda}}{\\Gamma(m+1)} = \\frac{\\lambda^me^{-\\lambda}}{m!}\n",
    "$$\n",
    "$$\n",
    "P(\\lambda|m, m') = \\frac{P_{\\lambda}(m)\\cdot P_{\\lambda}(m')\\cdot P(\\lambda)}{\\int P_{\\lambda'}(m)\\cdot P_{\\lambda'}(m')\\cdot P(\\lambda')d\\lambda'} = \\frac{\\frac{\\lambda^{(m+m')}}{m!\\cdot m'!}e^{-2\\lambda}}{\\int\\frac{\\lambda^{(m+m')}}{m!\\cdot m'!}e^{-2\\lambda}d\\lambda'} =  2^{(m+m')}\\frac{\\lambda^{(m+m')}e^{-2\\lambda}}{(m+m')!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f4f48",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ea790",
   "metadata": {},
   "source": [
    "A - Petya is sick; B - test is positive:\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)\\cdot P(A)}{P(B|A)\\cdot P(A) + P(B|!A)\\cdot P(!A)} = \\frac{0.99\\cdot10^{-5}}{0.99\\cdot10^{-5} + 0.01\\cdot(1-10^{-5})} = 0.1\\%\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d624fe",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6132e4",
   "metadata": {},
   "source": [
    "$$\n",
    "p(x) = \\frac{1}{Z}e^{-\\frac{x^TAx}{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a233b1",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58e6092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 1.24\n",
    "\n",
    "X = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y = np.sin(theta*X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b3ab5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(cv, alphas, steps, X, Y):\n",
    "    best = []\n",
    "    \n",
    "    gd_mse = pd.DataFrame(columns=['alpha', 'step', 'mse', 'theta'])\n",
    "    \n",
    "    rs = ShuffleSplit(n_splits=cv, random_state=45)\n",
    "    for alpha in alphas:\n",
    "        for step in steps:\n",
    "            errors = []\n",
    "            for Xtest_index in rs.split(X):\n",
    "                X_train, X_test = X[Xtest_index[0]], X[Xtest_index[1]]\n",
    "                y_train, y_test = Y[Xtest_index[0]], Y[Xtest_index[1]]\n",
    "                \n",
    "                fun = lambda theta: step*mse(y_train, np.sin(theta*X_train), squared=False) + step*alpha*np.abs(theta)\n",
    "                res = minimize(fun, 1, method='BFGS')\n",
    "                errors.append(mse(y_test, np.sin(res.x*X_test), squared=False))\n",
    "            new_row = pd.Series({'alpha': alpha, 'step': step, 'mse': min(errors), 'theta': res.x})\n",
    "            gd_mse = pd.concat([gd_mse, new_row.to_frame().T], ignore_index=True)\n",
    "    gd_mse = gd_mse.sort_values(by=['mse'], ascending=True, ignore_index=True)\n",
    "    return gd_mse.iloc[0]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "646e31de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha                0.000258\n",
       "step                   0.0505\n",
       "mse                       0.0\n",
       "theta    [1.2399999981798788]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = 3\n",
    "alphas = np.linspace(1e-5, 1e-3, 5)\n",
    "steps = np.linspace(1e-3, 1e-1, 5)\n",
    "cross_val(cv, alphas, steps, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386ebe3",
   "metadata": {},
   "source": [
    "## Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072eaf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Steels_kaggle.csv')\n",
    "\n",
    "X = df[[' C', ' Si', ' Mn', ' P', ' S', ' Ni', ' Cr', ' Mo',\n",
    "       ' Cu', 'V', ' Al', ' N', ' Temperature (Â°C)']]\n",
    "Y = df[' 0.2% Proof Stress (MPa)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7af02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 0.1 : [ -0.39858646   8.60751172  43.42987316 -10.48910529  -0.\n",
      "  16.74422098  11.92172192  16.70484622  -6.58473399  65.82482567\n",
      "  15.20034942  -6.52048216 -64.58762278]\n",
      "For alpha = 3.545 : [ -0.           7.34774404  34.48156118  -5.06301505  -0.\n",
      "  13.16247989   0.43034795  17.76702573  -0.          67.39796577\n",
      "  18.41505653  -0.         -60.38261788]\n",
      "For alpha = 6.99 : [ -0.           5.63528444  28.99163353  -1.77646184  -0.\n",
      "  15.39085719   0.           8.72437093  -0.          69.84062603\n",
      "  14.15260356  -0.         -56.52826551]\n",
      "For alpha = 10.434 : [ -0.           3.83078037  24.39144352  -0.          -0.\n",
      "  16.89800088   0.           0.          -0.          71.94900224\n",
      "  10.08680775  -0.         -52.72446168]\n",
      "For alpha = 13.879 : [ -0.           1.43583532  24.56101659  -0.          -0.\n",
      "  14.34535678   0.           0.          -0.          69.29747351\n",
      "   7.62623997  -0.         -49.0470367 ]\n",
      "For alpha = 17.324 : [ -0.           0.          24.67224048  -0.          -0.\n",
      "  12.09104627   0.           0.          -0.          66.30770439\n",
      "   4.74150293  -0.         -45.40727942]\n",
      "For alpha = 20.769 : [ -0.           0.          24.69016474  -0.          -0.\n",
      "  10.28500687   0.           0.           0.          62.81184296\n",
      "   1.22577186  -0.         -41.82409166]\n",
      "For alpha = 24.214 : [ -0.           0.          22.89375058  -0.          -0.\n",
      "   8.88402685   0.           0.           0.          59.47104289\n",
      "   0.          -0.         -38.2674052 ]\n",
      "For alpha = 27.659 : [  0.           0.          20.12707891  -0.          -0.\n",
      "   7.70097865   0.           0.           0.          56.21237524\n",
      "   0.          -0.         -34.72483356]\n",
      "For alpha = 31.103 : [  0.           0.          17.3588822   -0.          -0.\n",
      "   6.5189805    0.           0.           0.          52.95336929\n",
      "   0.          -0.         -31.1823242 ]\n",
      "For alpha = 34.548 : [  0.           0.          14.58864322  -0.          -0.\n",
      "   5.33838854   0.           0.           0.          49.69391031\n",
      "   0.          -0.         -27.63989824]\n",
      "For alpha = 37.993 : [  0.           0.          11.822847    -0.          -0.\n",
      "   4.15473755   0.           0.           0.          46.43543685\n",
      "   0.          -0.         -24.09729085]\n",
      "For alpha = 41.438 : [  0.           0.           9.05556899  -0.          -0.\n",
      "   2.97210684   0.           0.           0.          43.1766347\n",
      "   0.          -0.         -20.55474397]\n",
      "For alpha = 44.883 : [  0.           0.           6.28822131  -0.          -0.\n",
      "   1.78952409   0.           0.           0.          39.91781709\n",
      "   0.          -0.         -17.01219993]\n",
      "For alpha = 48.328 : [  0.           0.           3.52137988  -0.          -0.\n",
      "   0.60659278   0.           0.           0.          36.65911178\n",
      "   0.          -0.         -13.46963522]\n",
      "For alpha = 51.772 : [ 0.          0.          0.49764205 -0.         -0.          0.\n",
      "  0.          0.          0.         33.2085338   0.         -0.\n",
      " -9.93654663]\n",
      "For alpha = 55.217 : [ 0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.         29.54805454  0.         -0.\n",
      " -6.29563086]\n",
      "For alpha = 58.662 : [ 0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.         25.88618113  0.         -0.\n",
      " -2.63375336]\n",
      "For alpha = 62.107 : [ 0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.         22.28524708  0.          0.\n",
      " -0.        ]\n",
      "For alpha = 65.552 : [ 0.         0.         0.        -0.        -0.         0.\n",
      "  0.         0.         0.        18.8404195  0.         0.\n",
      " -0.       ]\n",
      "For alpha = 68.997 : [ 0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.         15.39559191  0.          0.\n",
      " -0.        ]\n",
      "For alpha = 72.441 : [ 0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.         11.95076432  0.          0.\n",
      " -0.        ]\n",
      "For alpha = 75.886 : [ 0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.          8.50593674  0.          0.\n",
      " -0.        ]\n",
      "For alpha = 79.331 : [ 0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.          5.06110915  0.          0.\n",
      " -0.        ]\n",
      "For alpha = 82.776 : [ 0.          0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.          1.61628157  0.          0.\n",
      " -0.        ]\n",
      "For alpha = 86.221 : [ 0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0.]\n",
      "For alpha = 89.666 : [ 0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0.]\n",
      "For alpha = 93.11 : [ 0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0.]\n",
      "For alpha = 96.555 : [ 0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0.]\n",
      "For alpha = 100.0 : [ 0.  0.  0. -0. -0.  0.  0.  0.  0.  0.  0.  0. -0.]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.linspace(1e-1, 100, 30)\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    print(\"For alpha =\", round(alpha, 3), \":\", lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329a282",
   "metadata": {},
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb23a4",
   "metadata": {},
   "source": [
    "$$\n",
    "|| y - Xw||_2 \\rightarrow min\n",
    "$$\n",
    "$$\n",
    "s.t. ||w||_1 \\leq C\n",
    "$$\n",
    "Lagrange multipliers method:\n",
    "$$\n",
    "L(w, \\lambda) = ||y - Xw||_2 - \\lambda(C - ||w||_1)\n",
    "$$\n",
    "The original problem is dual to the following problem:\n",
    "$$\n",
    "g(\\lambda) = \\max_{\\lambda > 0} \\left[\\min_{\\omega}\\left(||y - Xw||_2 + \\lambda ||w||_1\\right) - \\lambda C\\right]\n",
    "$$\n",
    "which is equivalent to\n",
    "$$\n",
    "\\max_{\\lambda > 0}\\min_{\\omega}\\left(||y - Xw||_2 + \\lambda ||w||_1 - \\lambda C\\right)\n",
    "$$\n",
    "which is equivalent to\n",
    "$$\n",
    "\\min_{\\omega}\\max_{\\lambda > 0}\\left(||y - Xw||_2 + \\lambda ||w||_1 - \\lambda C\\right)\n",
    "$$\n",
    "Finally, for some lambda, the task turned into\n",
    "$$\n",
    "\\min_{\\omega}\\left(||y - Xw||_2 + \\lambda ||w||_1 - \\lambda C\\right)\n",
    "$$\n",
    "which is equivalent to\n",
    "$$\n",
    "\\min_{\\omega}\\left(||y - Xw||_2 + \\lambda ||w||_1\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd1428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
